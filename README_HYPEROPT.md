# GraphPart è¶…å‚æ•°ä¼˜åŒ–ç³»ç»Ÿ

## ğŸ¯ ç›®æ ‡
åˆ›å»ºä¸€ä¸ªå…¨é¢çš„è¶…å‚æ•°è‡ªåŠ¨è°ƒä¼˜ç³»ç»Ÿï¼Œå®ç°ï¼š
- **CutæŸå¤±** < 0.02 (è¶Šä½è¶Šå¥½)
- **BalanceæŸå¤±** < 1e-3 (è¶Šä½è¶Šå¥½)  
- **KLæ•£åº¦** ä¿æŒçµæ´»æ€§
- **æ¨¡å‹è¾“å‡ºè´¨é‡** ä¸ä¼ ç»Ÿè¶…å›¾åˆ’åˆ†ç¨‹åºç›¸å½“ï¼Œæ— éœ€åå¤„ç†

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ ¸å¿ƒç»„ä»¶

```
GraphPart-HyperOpt/
â”œâ”€â”€ æ ¸å¿ƒä¼˜åŒ–æ¨¡å—/
â”‚   â”œâ”€â”€ hyperparameter_optimizer.py    # å¤šç­–ç•¥ä¼˜åŒ–å™¨
â”‚   â”œâ”€â”€ hyperopt_config.py            # æœç´¢ç©ºé—´é…ç½®
â”‚   â””â”€â”€ convergence_monitor.py        # æ”¶æ•›ç›‘æ§
â”œâ”€â”€ ç‰¹å¾å¤„ç†/
â”‚   â”œâ”€â”€ feature_normalizer.py         # å¢å¼ºç‰¹å¾å½’ä¸€åŒ–
â”‚   â””â”€â”€ enhanced_trainer.py          # å¢å¼ºè®­ç»ƒå™¨
â”œâ”€â”€ åˆ†æå·¥å…·/
â”‚   â”œâ”€â”€ analysis_tools.py             # å¯è§†åŒ–åˆ†æ
â”‚   â””â”€â”€ logger.py                    # æ—¥å¿—ç³»ç»Ÿ
â”œâ”€â”€ é…ç½®æ–‡ä»¶/
â”‚   â”œâ”€â”€ config_profiles.json         # é¢„è®¾é…ç½®
â”‚   â””â”€â”€ config.py                    # å…¨å±€é…ç½®
â””â”€â”€ è‡ªåŠ¨åŒ–è„šæœ¬/
    â”œâ”€â”€ run_hyperopt.sh              # è‡ªåŠ¨åŒ–è¿è¡Œè„šæœ¬
    â””â”€â”€ train_improved.py            # æ”¹è¿›è®­ç»ƒæ¨¡æ¿
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–
```bash
pip install torch torch-geometric optuna numpy scipy scikit-learn
pip install matplotlib seaborn plotly pandas
```

### 2. å‡†å¤‡æ•°æ®
å°†è¶…å›¾æ•°æ®æ–‡ä»¶(.hgræ ¼å¼)æ”¾å…¥`./data/`ç›®å½•ï¼š
```
data/
â”œâ”€â”€ ibm01.hgr
â”œâ”€â”€ ibm02.hgr
â””â”€â”€ ...
```

### 3. è¿è¡Œè‡ªåŠ¨åŒ–ä¼˜åŒ–
```bash
# å®Œæ•´ä¼˜åŒ–ï¼ˆ200ä¸ªè¯•éªŒï¼Œ24å°æ—¶ï¼‰
./run_hyperopt.sh --data-path ./data --output-dir ./results

# å¿«é€Ÿæµ‹è¯•ï¼ˆ20ä¸ªè¯•éªŒï¼Œ2å°æ—¶ï¼‰
./run_hyperopt.sh --data-path ./data --quick-test

# è‡ªå®šä¹‰é…ç½®
./run_hyperopt.sh --data-path ./data --n-trials 100 --n-parallel 4
```

### 4. æŸ¥çœ‹ç»“æœ
```bash
# ç”Ÿæˆåˆ†ææŠ¥å‘Š
python analysis_tools.py --results-dir ./results

# å¯åŠ¨äº¤äº’å¼ä»ªè¡¨æ¿
optuna-dashboard sqlite://./results/optuna_study.db
```

## ğŸ”§ é…ç½®é€‰é¡¹

### æœç´¢ç©ºé—´å‚æ•°

#### è®­ç»ƒå‚æ•°
- **å­¦ä¹ ç‡**: 1e-5 åˆ° 1e-2 (å¯¹æ•°å‡åŒ€åˆ†å¸ƒ)
- **è®­ç»ƒè½®æ•°**: 50 åˆ° 300
- **æƒé‡è¡°å‡**: 1e-6 åˆ° 1e-3

#### æŸå¤±å‡½æ•°æƒé‡ (å…³é”®å‚æ•°)
- **Î± (KLæƒé‡)**: 1e-5 åˆ° 1e-2 (ä¿æŒçµæ´»æ€§)
- **Î² (Cutæƒé‡)**: 3.0 åˆ° 30.0 (é«˜æƒé‡å®ç°ä½cutæŸå¤±)
- **Î³ (Balanceæƒé‡)**: 2.0 åˆ° 15.0 (é«˜æƒé‡å®ç°ä½balanceæŸå¤±)

#### ç‰¹å¾å½’ä¸€åŒ–æ–¹æ³•
- `standard`: æ ‡å‡†å½’ä¸€åŒ–ï¼ˆå½“å‰æ–¹æ³•ï¼‰
- `robust`: é²æ£’å½’ä¸€åŒ–ï¼ˆä½¿ç”¨ä¸­ä½æ•°å’ŒIQRï¼‰
- `unit_norm`: å•ä½èŒƒæ•°å½’ä¸€åŒ–
- `min_max`: æœ€å°-æœ€å¤§ç¼©æ”¾
- `z_score`: Z-scoreæ ‡å‡†åŒ–
- `power`: å¹‚å˜æ¢+æ ‡å‡†åŒ–

#### æ¨¡å‹æ¶æ„
- **éšè—ç»´åº¦**: [128, 256, 512, 768]
- **æ½œåœ¨ç»´åº¦**: [32, 64, 128, 256]
- **Dropoutç‡**: 0.0 åˆ° 0.5
- **Maskç‡**: 0.1 åˆ° 0.4

### é¢„è®¾é…ç½®æ–‡ä»¶

#### æ¿€è¿›ä¼˜åŒ– (aggressive)
```json
{
  "learning_rate": 1e-4,
  "epochs": 250,
  "alpha": 0.0001,
  "beta": 25.0,
  "gamma": 10.0,
  "hidden_dim": 512,
  "adaptive_weights": true,
  "norm_method": "robust"
}
```

#### å¹³è¡¡æ–¹æ³• (balanced)
```json
{
  "learning_rate": 5e-5,
  "epochs": 150,
  "alpha": 0.0005,
  "beta": 15.0,
  "gamma": 5.0,
  "hidden_dim": 256,
  "norm_method": "standard"
}
```

## ğŸ“Š ç›‘æ§æŒ‡æ ‡

### æ”¶æ•›æ ‡å‡†
- **CutæŸå¤±é˜ˆå€¼**: â‰¤ 0.02
- **BalanceæŸå¤±é˜ˆå€¼**: â‰¤ 1e-3
- **ç¨³å®šæ€§çª—å£**: 10ä¸ªepoch
- **æœ€å°æ”¹å–„**: 1e-5

### è´¨é‡è¯„ä¼°
- **åˆ’åˆ†è´¨é‡å¾—åˆ†**: ä¸åŸºçº¿æ–¹æ³•æ¯”è¾ƒ
- **å¹³è¡¡å¾—åˆ†**: åˆ†åŒºå¤§å°å‡åŒ€æ€§
- **æ•´ä½“è´¨é‡**: ç»¼åˆè¯„åˆ† (0.6 Ã— cut_quality + 0.4 Ã— balance_score)

## ğŸ› ï¸ é«˜çº§åŠŸèƒ½

### 1. è‡ªé€‚åº”æŸå¤±æƒé‡
ç³»ç»Ÿå¯ä»¥å­¦ä¹ æœ€ä¼˜çš„æŸå¤±å‡½æ•°æƒé‡ï¼š
```python
loss_weighter = AdaptiveLossWeighting(
    adaptive=True,      # å¯ç”¨è‡ªé€‚åº”æƒé‡
    annealing=True      # å¯ç”¨é€€ç«ç­–ç•¥
)
```

### 2. å¤šé˜¶æ®µä¼˜åŒ–
- **ç²—æœç´¢**: å¹¿æ³›æ¢ç´¢å‚æ•°ç©ºé—´
- **ç²¾è°ƒ**: åœ¨æœ€ä½³åŒºåŸŸç»†åŒ–æœç´¢  
- **æœ€ç»ˆéªŒè¯**: é•¿æ—¶é—´è®­ç»ƒéªŒè¯

### 3. æ—©åœå’Œå‰ªæ
- **æ—©åœ**: é˜²æ­¢è¿‡æ‹Ÿåˆ
- **è¯•éªŒå‰ªæ**: æå‰ç»ˆæ­¢æ— å‰é€”çš„è¯•éªŒ
- **æ¢¯åº¦å‰ªè£**: é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸

### 4. æ•°å€¼ç¨³å®šæ€§
- **é™¤é›¶ä¿æŠ¤**: åœ¨æŸå¤±å‡½æ•°ä¸­æ·»åŠ epsilon
- **æ¢¯åº¦èŒƒå›´é™åˆ¶**: åŒå‘clamp
- **NaNæ£€æµ‹**: è‡ªåŠ¨è·³è¿‡å¼‚å¸¸æ ·æœ¬

## ğŸ“ˆ ç»“æœåˆ†æ

### å¯è§†åŒ–å·¥å…·
1. **æ”¶æ•›å›¾**: æŸå¤±éšè¯•éªŒå˜åŒ–
2. **å‚æ•°é‡è¦æ€§**: å“ªäº›å‚æ•°æœ€å…³é”®
3. **å¸•ç´¯æ‰˜å‰æ²¿**: å¤šç›®æ ‡ä¼˜åŒ–å¯è§†åŒ–
4. **ç›¸å…³æ€§çƒ­å›¾**: å‚æ•°é—´ç›¸å…³æ€§
5. **æ¼”åŒ–åŠ¨ç”»**: æŸå¤±æ¼”åŒ–è¿‡ç¨‹

### åˆ†ææŠ¥å‘Š
ç³»ç»Ÿè‡ªåŠ¨ç”ŸæˆåŒ…å«ä»¥ä¸‹å†…å®¹çš„HTMLæŠ¥å‘Šï¼š
- ç›®æ ‡è¾¾æˆæƒ…å†µ
- æœ€ä½³é…ç½®å‚æ•°
- ç»Ÿè®¡åˆ†æç»“æœ
- å¯è§†åŒ–å›¾è¡¨
- æ”¹è¿›å»ºè®®

## ğŸ¯ ä½¿ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹1: è¾¾åˆ°æä½CutæŸå¤±
```bash
# ä¸“é—¨é’ˆå¯¹cutæŸå¤±ä¼˜åŒ–
python enhanced_trainer.py \
  --config config_profiles.json:cut_focused \
  --data-path ./data \
  --beta 30 --gamma 5
```

### æ¡ˆä¾‹2: å¹³è¡¡æ‰€æœ‰ç›®æ ‡
```bash
# ä½¿ç”¨å¹³è¡¡é…ç½®
python enhanced_trainer.py \
  --config config_profiles.json:balanced \
  --data-path ./data
```

### æ¡ˆä¾‹3: å¿«é€ŸéªŒè¯
```bash
# å¿«é€Ÿæµ‹è¯•é…ç½®
python enhanced_trainer.py \
  --config config_profiles.json:quick_test \
  --data-path ./data \
  --epochs 30
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. æŸå¤±ä¸æ”¶æ•›
- **è§£å†³æ–¹æ¡ˆ**: å¢åŠ Î²å’ŒÎ³æƒé‡ï¼Œé™ä½å­¦ä¹ ç‡
- **æ£€æŸ¥**: ç‰¹å¾å½’ä¸€åŒ–æ˜¯å¦æ­£ç¡®

#### 2. NaNæŸå¤±
- **è§£å†³æ–¹æ¡ˆ**: å¯ç”¨æ¢¯åº¦å‰ªè£ï¼Œæ£€æŸ¥æ•°æ®è´¨é‡
- **é¢„é˜²**: ä½¿ç”¨æ•°å€¼ç¨³å®šçš„å®ç°

#### 3. å†…å­˜ä¸è¶³
- **è§£å†³æ–¹æ¡ˆ**: å‡å°‘æ‰¹å¤§å°ï¼Œå¯ç”¨å†…å­˜æ¸…ç†
- **ä¼˜åŒ–**: ä½¿ç”¨æ›´å°çš„æ¨¡å‹ç»´åº¦

#### 4. ä¼˜åŒ–åœæ»
- **è§£å†³æ–¹æ¡ˆ**: æ‰©å¤§æœç´¢ç©ºé—´ï¼Œå¢åŠ è¯•éªŒæ•°é‡
- **è°ƒè¯•**: æ£€æŸ¥å‚æ•°é‡è¦æ€§åˆ†æ

### æ€§èƒ½ä¼˜åŒ–

#### GPUä½¿ç”¨
```python
# è‡ªåŠ¨è®¾å¤‡æ£€æµ‹
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```

#### å¹¶è¡Œä¼˜åŒ–
```bash
# ä½¿ç”¨å¤šä¸ªå¹¶è¡Œworker
./run_hyperopt.sh --n-parallel 8
```

#### å†…å­˜ç®¡ç†
```python
# é«˜æ•ˆå†…å­˜æ¸…ç†
del W, Y, D
if torch.cuda.is_available():
    torch.cuda.empty_cache()
```

## ğŸ“‹ æœ€ä½³å®è·µ

### 1. æ•°æ®å‡†å¤‡
- ç¡®ä¿.hgræ–‡ä»¶æ ¼å¼æ­£ç¡®
- è¿‡æ»¤è¿‡å¤§çš„è¶…è¾¹ï¼ˆ> 1000èŠ‚ç‚¹ï¼‰
- æ£€æŸ¥æ•°æ®è´¨é‡å’Œå®Œæ•´æ€§

### 2. å‚æ•°è°ƒä¼˜ç­–ç•¥
- **ç¬¬ä¸€é˜¶æ®µ**: ä½¿ç”¨aggressiveé…ç½®å¿«é€Ÿæµ‹è¯•
- **ç¬¬äºŒé˜¶æ®µ**: è¿è¡Œå®Œæ•´ä¼˜åŒ–æ‰¾åˆ°æœ€ä½³åŒºåŸŸ
- **ç¬¬ä¸‰é˜¶æ®µ**: ç²¾è°ƒæœ€ä½³é…ç½®å¹¶éªŒè¯

### 3. ç›‘æ§å’Œè°ƒè¯•
- ç›‘æ§è®­ç»ƒæ—¥å¿—ä¸­çš„æŸå¤±è¶‹åŠ¿
- ä½¿ç”¨å¯è§†åŒ–å·¥å…·åˆ†æå‚æ•°é‡è¦æ€§
- å®šæœŸæ£€æŸ¥æ”¶æ•›çŠ¶æ€

### 4. ç”Ÿäº§éƒ¨ç½²
- ä¿å­˜æœ€ä½³æ¨¡å‹é…ç½®
- åœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠéªŒè¯
- å»ºç«‹æ€§èƒ½åŸºå‡†

## ğŸ¤ æ‰©å±•æ¥å£

### è‡ªå®šä¹‰æŸå¤±å‡½æ•°
```python
class CustomLossWeighting(AdaptiveLossWeighting):
    def forward(self, kl_loss, cut_loss, balance_loss):
        # è‡ªå®šä¹‰æŸå¤±ç»„åˆé€»è¾‘
        return custom_loss, weights_info
```

### è‡ªå®šä¹‰ç‰¹å¾å½’ä¸€åŒ–
```python
class CustomNormalizer(FeatureNormalizer):
    def normalize_features(self, features, reference_idx=4):
        # è‡ªå®šä¹‰å½’ä¸€åŒ–é€»è¾‘
        return normalized_features
```

### è‡ªå®šä¹‰ä¼˜åŒ–ç­–ç•¥
```python
def custom_objective(trial):
    params = sample_custom_parameters(trial)
    return train_and_evaluate(params)
```

## ğŸ“ æ”¯æŒä¸ç»´æŠ¤

### æ—¥å¿—ä½ç½®
- è®­ç»ƒæ—¥å¿—: `./results/logs/training_*.log`
- ä¼˜åŒ–æ—¥å¿—: `./results/logs/hyperopt_*.log`
- é”™è¯¯æ—¥å¿—: `./results/logs/error_*.log`

### ç»“æœæ–‡ä»¶
- æœ€ä½³é…ç½®: `./results/best_config.json`
- å®Œæ•´ç»“æœ: `./results/optimization_results.json`
- æ¨¡å‹æ–‡ä»¶: `./results/models/final_model.pt`
- åˆ†ææŠ¥å‘Š: `./results/analysis/analysis_report.html`

### ç‰ˆæœ¬å…¼å®¹æ€§
- Python: â‰¥ 3.7
- PyTorch: â‰¥ 1.9
- PyTorch Geometric: â‰¥ 2.0
- Optuna: â‰¥ 3.0

---

*æœ¬æ–‡æ¡£éšç³»ç»Ÿæ›´æ–°æŒç»­ç»´æŠ¤ã€‚å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ•…éšœæ’é™¤ç« èŠ‚æˆ–æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ã€‚*